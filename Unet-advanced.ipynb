{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"n01z3\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import random\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "import shapely.wkt\n",
    "import shapely.affinity\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_Cls = 10\n",
    "inDir = '../input'\n",
    "DF = pd.read_csv(inDir + '/train_wkt_v4.csv')\n",
    "GS = pd.read_csv(inDir + '/grid_sizes.csv', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n",
    "SB = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\n",
    "ISZ = 160\n",
    "smooth = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _convert_coordinates_to_raster(coords, img_size, xymax):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    Xmax, Ymax = xymax\n",
    "    H, W = img_size\n",
    "    W1 = 1.0 * W * W / (W + 1)\n",
    "    H1 = 1.0 * H * H / (H + 1)\n",
    "    xf = W1 / Xmax\n",
    "    yf = H1 / Ymax\n",
    "    coords[:, 1] *= yf\n",
    "    coords[:, 0] *= xf\n",
    "    coords_int = np.round(coords).astype(np.int32)\n",
    "    return coords_int\n",
    "\n",
    "\n",
    "def _get_xmax_ymin(grid_sizes_panda, imageId):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    xmax, ymin = grid_sizes_panda[grid_sizes_panda.ImageId == imageId].iloc[0, 1:].astype(float)\n",
    "    return (xmax, ymin)\n",
    "\n",
    "\n",
    "def _get_polygon_list(wkt_list_pandas, imageId, cType):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n",
    "    multipoly_def = df_image[df_image.ClassType == cType].MultipolygonWKT\n",
    "    polygonList = None\n",
    "    if len(multipoly_def) > 0:\n",
    "        assert len(multipoly_def) == 1\n",
    "        polygonList = wkt_loads(multipoly_def.values[0])\n",
    "    return polygonList\n",
    "\n",
    "\n",
    "def _get_and_convert_contours(polygonList, raster_img_size, xymax):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    perim_list = []\n",
    "    interior_list = []\n",
    "    if polygonList is None:\n",
    "        return None\n",
    "    for k in range(len(polygonList)):\n",
    "        poly = polygonList[k]\n",
    "        perim = np.array(list(poly.exterior.coords))\n",
    "        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n",
    "        perim_list.append(perim_c)\n",
    "        for pi in poly.interiors:\n",
    "            interior = np.array(list(pi.coords))\n",
    "            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n",
    "            interior_list.append(interior_c)\n",
    "    return perim_list, interior_list\n",
    "\n",
    "\n",
    "def _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    img_mask = np.zeros(raster_img_size, np.uint8)\n",
    "    if contours is None:\n",
    "        return img_mask\n",
    "    perim_list, interior_list = contours\n",
    "    cv2.fillPoly(img_mask, perim_list, class_value)\n",
    "    cv2.fillPoly(img_mask, interior_list, 0)\n",
    "    return img_mask\n",
    "\n",
    "\n",
    "def generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda=GS, wkt_list_pandas=DF):\n",
    "    # __author__ = visoft\n",
    "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
    "    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)\n",
    "    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)\n",
    "    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)\n",
    "    mask = _plot_mask_from_contours(raster_size, contours, 1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def M(image_id):\n",
    "    # __author__ = amaia\n",
    "    # https://www.kaggle.com/aamaia/dstl-satellite-imagery-feature-detection/rgb-using-m-bands-example\n",
    "    img = tiff.imread('sixteen_band/{}_M.tif'.format(image_id))\n",
    "    img = np.rollaxis(img, 0, 3)\n",
    "    return img\n",
    "\n",
    "\n",
    "def stretch_n(bands, lower_percent=0, higher_percent=100):\n",
    "    out = np.zeros_like(bands, dtype=np.float32)\n",
    "    n = bands.shape[2]\n",
    "    for i in range(n):\n",
    "        a = 0  # np.min(band)\n",
    "        b = 1  # np.max(band)\n",
    "        c = np.percentile(bands[:, :, i], lower_percent)\n",
    "        d = np.percentile(bands[:, :, i], higher_percent)\n",
    "        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n",
    "        t[t < a] = a\n",
    "        t[t > b] = b\n",
    "        out[:, :, i] = t\n",
    "\n",
    "    return out.astype(np.float32)\n",
    "\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def stick_all_train():\n",
    "    print(\"let's stick all imgs together\")\n",
    "    s = 835\n",
    "\n",
    "    x = np.zeros((5 * s, 5 * s, 8))\n",
    "    y = np.zeros((5 * s, 5 * s, N_Cls))\n",
    "\n",
    "    ids = sorted(DF.ImageId.unique())\n",
    "    print(len(ids))\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            id = ids[5 * i + j]\n",
    "\n",
    "            img = M(id)\n",
    "            img = stretch_n(img)\n",
    "            print(img.shape, id, np.amax(img), np.amin(img))\n",
    "            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n",
    "            for z in range(N_Cls):\n",
    "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
    "                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n",
    "\n",
    "    print(np.amax(y), np.amin(y))\n",
    "\n",
    "    np.save('../input/data/x_trn_%d' % N_Cls, x)\n",
    "    np.save('../input/data/y_trn_%d' % N_Cls, y)\n",
    "\n",
    "\n",
    "def get_patches(img, msk, amt=10000, aug=True):\n",
    "    is2 = int(1.0 * ISZ)\n",
    "    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n",
    "\n",
    "    x, y = [], []\n",
    "\n",
    "    tr = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]\n",
    "    for i in range(amt):\n",
    "        xc = random.randint(0, xm)\n",
    "        yc = random.randint(0, ym)\n",
    "\n",
    "        im = img[xc:xc + is2, yc:yc + is2]\n",
    "        ms = msk[xc:xc + is2, yc:yc + is2]\n",
    "\n",
    "        for j in range(N_Cls):\n",
    "            sm = np.sum(ms[:, :, j])\n",
    "            if 1.0 * sm / is2 ** 2 > tr[j]:\n",
    "                if aug:\n",
    "                    if random.uniform(0, 1) > 0.5:\n",
    "                        im = im[::-1]\n",
    "                        ms = ms[::-1]\n",
    "                    if random.uniform(0, 1) > 0.5:\n",
    "                        im = im[:, ::-1]\n",
    "                        ms = ms[:, ::-1]\n",
    "\n",
    "                x.append(im)\n",
    "                y.append(ms)\n",
    "\n",
    "    x, y = 2 * np.transpose(x, (0, 3, 1, 2)) - 1, np.transpose(y, (0, 3, 1, 2))\n",
    "    print(x.shape, y.shape, np.amax(x), np.amin(x), np.amax(y), np.amin(y))\n",
    "    return x, y\n",
    "\n",
    "def make_val():\n",
    "    print(\"let's pick some samples for validation\")\n",
    "    img = np.load('../input/data/x_trn_%d.npy' % N_Cls)\n",
    "    msk = np.load('../input/data/y_trn_%d.npy' % N_Cls)\n",
    "    x, y = get_patches(img, msk, amt=3000)\n",
    "\n",
    "    np.save('../input/data/x_tmp_%d' % N_Cls, x)\n",
    "    np.save('../input/data/y_tmp_%d' % N_Cls, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "    inputs = Input((8, ISZ, ISZ))\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(inputs)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(N_Cls, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_jacc(model):\n",
    "    img = np.load('../input/data/x_tmp_%d.npy' % N_Cls)\n",
    "    msk = np.load('../input/data/y_tmp_%d.npy' % N_Cls)\n",
    "\n",
    "    prd = model.predict(img, batch_size=4)\n",
    "    print(prd.shape, msk.shape)\n",
    "    avg, trs = [], []\n",
    "\n",
    "    for i in range(N_Cls):\n",
    "        t_msk = msk[:, i, :, :]\n",
    "        t_prd = prd[:, i, :, :]\n",
    "        t_msk = t_msk.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
    "        t_prd = t_prd.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
    "\n",
    "        m, b_tr = 0, 0\n",
    "        for j in range(10):\n",
    "            tr = j / 10.0\n",
    "            pred_binary_mask = t_prd > tr\n",
    "\n",
    "            jk = jaccard_similarity_score(t_msk, pred_binary_mask)\n",
    "            if jk > m:\n",
    "                m = jk\n",
    "                b_tr = tr\n",
    "        print(i, m, b_tr)\n",
    "        avg.append(m)\n",
    "        trs.append(b_tr)\n",
    "\n",
    "    score = sum(avg) / 10.0\n",
    "    return score, trs\n",
    "\n",
    "\n",
    "def mask_for_polygons(polygons, im_size):\n",
    "    # __author__ = Konstantin Lopuhin\n",
    "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
    "    img_mask = np.zeros(im_size, np.uint8)\n",
    "    if not polygons:\n",
    "        return img_mask\n",
    "    int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
    "    exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n",
    "    interiors = [int_coords(pi.coords) for poly in polygons\n",
    "                 for pi in poly.interiors]\n",
    "    cv2.fillPoly(img_mask, exteriors, 1)\n",
    "    cv2.fillPoly(img_mask, interiors, 0)\n",
    "    return img_mask\n",
    "\n",
    "\n",
    "def mask_to_polygons(mask, epsilon=1, min_area=1.):\n",
    "    # __author__ = Konstantin Lopuhin\n",
    "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
    "\n",
    "    # first, find contours with cv2: it's much faster than shapely\n",
    "    image, contours, hierarchy = cv2.findContours(\n",
    "        ((mask == 1) * 255).astype(np.uint8),\n",
    "        cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "    # create approximate contours to have reasonable submission size\n",
    "    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n",
    "                       for cnt in contours]\n",
    "    if not contours:\n",
    "        return MultiPolygon()\n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(approx_contours[idx])\n",
    "    # create actual polygons filtering by area (removes artifacts)\n",
    "    all_polygons = []\n",
    "    for idx, cnt in enumerate(approx_contours):\n",
    "        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n",
    "            assert cnt.shape[1] == 1\n",
    "            poly = Polygon(\n",
    "                shell=cnt[:, 0, :],\n",
    "                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n",
    "                       if cv2.contourArea(c) >= min_area])\n",
    "            all_polygons.append(poly)\n",
    "    # approximating polygons might have created invalid ones, fix them\n",
    "    all_polygons = MultiPolygon(all_polygons)\n",
    "    if not all_polygons.is_valid:\n",
    "        all_polygons = all_polygons.buffer(0)\n",
    "        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n",
    "        # need to keep it a Multi throughout\n",
    "        if all_polygons.type == 'Polygon':\n",
    "            all_polygons = MultiPolygon([all_polygons])\n",
    "    return all_polygons\n",
    "\n",
    "\n",
    "def get_scalers(im_size, x_max, y_min):\n",
    "    # __author__ = Konstantin Lopuhin\n",
    "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
    "    h, w = im_size  # they are flipped so that mask_for_polygons works correctly\n",
    "    h, w = float(h), float(w)\n",
    "    w_ = 1.0 * w * (w / (w + 1))\n",
    "    h_ = 1.0 * h * (h / (h + 1))\n",
    "    return w_ / x_max, h_ / y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net():\n",
    "    print(\"start train net\")\n",
    "    x_val, y_val = np.load('../input/data/x_tmp_%d.npy' % N_Cls), np.load('data/y_tmp_%d.npy' % N_Cls)\n",
    "    img = np.load('../input/data/x_trn_%d.npy' % N_Cls)\n",
    "    msk = np.load('../input/data/y_trn_%d.npy' % N_Cls)\n",
    "\n",
    "    x_trn, y_trn = get_patches(img, msk)\n",
    "\n",
    "    model = get_unet()\n",
    "    model.load_weights('../input/weights/unet_10_jk0.7878')\n",
    "    model_checkpoint = ModelCheckpoint('../input/weights/unet_tmp.hdf5', monitor='loss', save_best_only=True)\n",
    "    for i in range(1):\n",
    "        model.fit(x_trn, y_trn, batch_size=64, nb_epoch=1, verbose=1, shuffle=True,\n",
    "                  callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n",
    "        del x_trn\n",
    "        del y_trn\n",
    "        x_trn, y_trn = get_patches(img, msk)\n",
    "        score, trs = calc_jacc(model)\n",
    "        print('val jk', score)\n",
    "        model.save_weights('../input/weights/unet_10_jk%.4f' % score)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_id(id, model, trs):\n",
    "    img = M(id)\n",
    "    x = stretch_n(img)\n",
    "\n",
    "    cnv = np.zeros((960, 960, 8)).astype(np.float32)\n",
    "    prd = np.zeros((N_Cls, 960, 960)).astype(np.float32)\n",
    "    cnv[:img.shape[0], :img.shape[1], :] = x\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        line = []\n",
    "        for j in range(0, 6):\n",
    "            line.append(cnv[i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ])\n",
    "\n",
    "        x = 2 * np.transpose(line, (0, 3, 1, 2)) - 1\n",
    "        tmp = model.predict(x, batch_size=4)\n",
    "        for j in range(tmp.shape[0]):\n",
    "            prd[:, i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ] = tmp[j]\n",
    "\n",
    "    trs = [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1]\n",
    "    for i in range(N_Cls):\n",
    "        prd[i] = prd[i] > trs[i]\n",
    "\n",
    "    return prd[:, :img.shape[0], :img.shape[1]]\n",
    "\n",
    "\n",
    "def predict_test(model, trs = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]):\n",
    "    print(\"predict test\")\n",
    "    for i, id in enumerate(sorted(set(SB['ImageId'].tolist()))):\n",
    "        msk = predict_id(id, model, trs)\n",
    "        np.save('../input/msk/10_%s' % id, msk)\n",
    "        if i % 100 == 0: print(i, id)\n",
    "\n",
    "\n",
    "def make_submit():\n",
    "    print(\"make submission file\")\n",
    "    df = pd.read_csv('sample_submission.csv')\n",
    "    print(df.head())\n",
    "    for idx, row in df.iterrows():\n",
    "        id = row[0]\n",
    "        kls = row[1] - 1\n",
    "\n",
    "        msk = np.load('../input/msk/10_%s.npy' % id)[kls]\n",
    "        pred_polygons = mask_to_polygons(msk)\n",
    "        x_max = GS.loc[GS['ImageId'] == id, 'Xmax'].as_matrix()[0]\n",
    "        y_min = GS.loc[GS['ImageId'] == id, 'Ymin'].as_matrix()[0]\n",
    "\n",
    "        x_scaler, y_scaler = get_scalers(msk.shape, x_max, y_min)\n",
    "\n",
    "        scaled_pred_polygons = shapely.affinity.scale(pred_polygons, xfact=1.0 / x_scaler, yfact=1.0 / y_scaler,\n",
    "                                                      origin=(0, 0, 0))\n",
    "\n",
    "        df.iloc[idx, 2] = shapely.wkt.dumps(scaled_pred_polygons)\n",
    "        if idx % 100 == 0: print(idx)\n",
    "    print(df.head())\n",
    "    df.to_csv('../input/subm/1.csv', index=False)\n",
    "\n",
    "\n",
    "def check_predict(id='6120_2_3'):\n",
    "    model = get_unet()\n",
    "    model.load_weights('../input/weights/unet_10_jk0.7878')\n",
    "\n",
    "    msk = predict_id(id, model, [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1])\n",
    "    img = M(id)\n",
    "\n",
    "    plt.figure()\n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.set_title('image ID:6120_2_3')\n",
    "    ax1.imshow(img[:, :, 5], cmap=plt.get_cmap('gist_ncar'))\n",
    "    ax2 = plt.subplot(132)\n",
    "    ax2.set_title('predict bldg pixels')\n",
    "    ax2.imshow(msk[0], cmap=plt.get_cmap('gray'))\n",
    "    ax3 = plt.subplot(133)\n",
    "    ax3.set_title('predict bldg polygones')\n",
    "    ax3.imshow(mask_for_polygons(mask_to_polygons(msk[0], epsilon=1), img.shape[:2]), cmap=plt.get_cmap('gray'))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `InputLayer` call to the Keras 2 API: `InputLayer(batch_input_shape=[None, 8, ..., sparse=False, name=\"input_8\", dtype=\"float32\")`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_134\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=32, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_135\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=32, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(name=\"maxpooling2d_29\", trainable=True, pool_size=[2, 2], strides=[2, 2], padding=\"valid\", data_format=\"channels_first\")`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_136\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=64, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_137\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=64, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(name=\"maxpooling2d_30\", trainable=True, pool_size=[2, 2], strides=[2, 2], padding=\"valid\", data_format=\"channels_first\")`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_138\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=128, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_139\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=128, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(name=\"maxpooling2d_31\", trainable=True, pool_size=[2, 2], strides=[2, 2], padding=\"valid\", data_format=\"channels_first\")`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_140\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=256, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_141\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=256, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(name=\"maxpooling2d_32\", trainable=True, pool_size=[2, 2], strides=[2, 2], padding=\"valid\", data_format=\"channels_first\")`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_142\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=512, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_143\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=512, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_144\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=256, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_145\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=256, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_146\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=128, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_147\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=128, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_148\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=64, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_149\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=64, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_150\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=32, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_151\", activity_regularizer=None, trainable=True, activation=\"relu\", kernel_size=(3, 3), filters=32, strides=[1, 1], padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n",
      "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:1252: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(name=\"convolution2d_152\", activity_regularizer=None, trainable=True, activation=\"sigmoid\", kernel_size=(1, 1), filters=10, strides=[1, 1], padding=\"valid\", data_format=\"channels_first\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None, use_bias=True)`\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 1 in both shapes must be equal, but are 10 and 20 for 'merge_29/concat' (op: 'ConcatV2') with input shapes: [?,1024,20,10], [?,256,20,20], [] and with computed input tensors: input[2] = <1>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 10 and 20 for 'merge_29/concat' (op: 'ConcatV2') with input shapes: [?,1024,20,10], [?,256,20,20], [] and with computed input tensors: input[2] = <1>.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-239abc6a46c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/weights/unet_42quality.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'jaccard_coef'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaccard_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jaccard_coef_int'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjaccard_coef_int\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredict_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmake_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    311\u001b[0m                         \u001b[0;34m'Maybe you meant to use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     52\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    138\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 139\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2495\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2497\u001b[0;31m                         \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   2454\u001b[0m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2455\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2456\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2458\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'concat'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mul'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(tensors, axis)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   return gen_array_ops._concat_v2(values=values,\n\u001b[1;32m   1065\u001b[0m                                   \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                                   name=name)\n\u001b[0m\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_concat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    491\u001b[0m   \"\"\"\n\u001b[1;32m    492\u001b[0m   result = _op_def_lib.apply_op(\"ConcatV2\", values=values, axis=axis,\n\u001b[0;32m--> 493\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m    494\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 10 and 20 for 'merge_29/concat' (op: 'ConcatV2') with input shapes: [?,1024,20,10], [?,256,20,20], [] and with computed input tensors: input[2] = <1>."
     ]
    }
   ],
   "source": [
    "model = load_model('../input/weights/unet_42quality.hdf5', custom_objects={'jaccard_coef': jaccard_coef, 'jaccard_coef_int': jaccard_coef_int})\n",
    "\n",
    "predict_test(model)\n",
    "make_submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
